%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%
%
\chapter{Tensor relations from bivector field equation}\label{chap:PJMaxwellTensor}
\index{Maxwell's equations!tensor}
%\date{Sept 7, 2008.  maxwellToTensor.tex}

\section{Motivation}

This contains a somewhat unstructured collection of notes translating between tensor and bivector forms of Maxwell's equation(s).

\section{Electrodynamic tensor}

John Denker's paper \citep{DenkerMaxwell} writes:

\begin{equation}
F = (\BE + ic\BB) \gamma_0,
\end{equation}

with
\begin{equation}\label{eqn:maxwellToTensor:20}
\begin{aligned}
\BE &= E^i \gamma_i \\
\BB &= B^i \gamma_i.
\end{aligned}
\end{equation}

Since he uses the positive end of the metric for spatial indices this works fine.  Contrast to \citep{doran2003gap} who write:

\begin{equation}
F = \BE + ic\BB,
\end{equation}

with the following implied spatial bivector representation:
\begin{equation}\label{eqn:maxwellToTensor:40}
\begin{aligned}
\BE &= E^i \sigma_i = E^i \gamma_{i0} \\
\BB &= B^i \sigma_i = B^i \gamma_{i0}.
\end{aligned}
\end{equation}

That implied representation was not obvious to me, but I eventually figured out what they meant.  They also use \(c=1\), so I have added it back in here for clarity.

The end result in both cases is a pure bivector representation for the complete field:

\begin{equation*}
F = E^j \gamma_{j0} + ic B^j \gamma_{j0}.
\end{equation*}

%ASIDE: Is bivector the term used for a completely grade two multivector, but not neccessarily a wedge product?
%This field multivector is not definitely not a blade a term reserved for something that can be created by wedging (simple element in grassman algebra terms).
%Here the field multivector cannot be expressed as the wedge product of two vectors unless one of the electric or magnetic fields is entirely zero (essentially
%reducing the dimension of the spanning basis to a 3D bivector).

Let us look at the \(B^j\) basis bivectors a bit more closely:

\begin{equation*}
i\gamma_{j0}
= \gamma_{0123j0}
= -\gamma_{01230j}
= +\gamma_{00123j}
= (\gamma_0)^2 \gamma_{123j}.
\end{equation*}

Where,
\begin{equation*}
\gamma_{123j} =
\left\{
\begin{array}{l l}
(\gamma_{j})^2 \gamma_{23} & \quad \mbox{if \(j = 1\)} \\
(\gamma_{j})^2 \gamma_{31} & \quad \mbox{if \(j = 2\)} \\
(\gamma_{j})^2 \gamma_{12} & \quad \mbox{if \(j = 3\)}.
\end{array} \right.
\end{equation*}

Combining these results we have a \((\gamma_0)^2 (\gamma_{j})^2 = -1\) coefficient that is metric invariant, and can write:

\begin{equation*}
i \sigma_{j} =
i \gamma_{j0} =
\left\{
\begin{array}{l l}
\gamma_{32} & \quad \mbox{if \(j = 1\)} \\
\gamma_{13} & \quad \mbox{if \(j = 2\)} \\
\gamma_{21} & \quad \mbox{if \(j = 3\)}.
\end{array} \right.
\end{equation*}

% -1:23
% -2:31
% -3:12

Or, more compactly:

\begin{equation*}
i \sigma_{a} =
i \gamma_{a0} =
-\epsilon_{abc} \gamma_{bc}.
\end{equation*}

Putting things back together, our bivector field in index notation is:

\begin{equation}\label{eqn:maxToTensor:Fcomp}
F = E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k}.
\end{equation}

\subsection{Tensor components}

Now, given a grade two multivector such as our field, how can we in general compute the components of that field given any arbitrary basis.  This can be done using the reciprocal bivector frame:

\begin{equation*}
F = \sum a_{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu}).
\end{equation*}

To calculate the coordinates \(a_{{\mu} {\nu}}\) we can dot with
\(e^{\nu} \wedge e^{\mu}\):

\begin{equation}\label{eqn:maxwellToTensor:60}
\begin{aligned}
F \cdot (e^{\nu} \wedge e^{\mu})
&= \sum a_{{\alpha} {\beta}} (e_{\alpha} \wedge e_{\beta}) \cdot (e^{\nu} \wedge e^{\mu}) \\
&= ( a_{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu}) + a_{{\nu} {\mu}} (e_{\nu} \wedge e_{\mu}) ) \cdot (e^{\nu} \wedge e^{\mu}) \\
&= a_{{\mu} {\nu}} - a_{{\nu} {\mu}} \\
&= 2 a_{{\mu} {\nu}}.
\end{aligned}
\end{equation}

Therefore
\begin{equation*}
F = \inv{2} \sum (F \cdot (e^{\nu} \wedge e^{\mu})) (e_{\mu} \wedge e_{\nu}) = \sum_{{\mu}<{\nu}} (F \cdot (e^{\nu} \wedge e^{\mu})) (e_{\mu} \wedge e_{\nu}).
\end{equation*}

With \(F^{{\mu} {\nu}} = F \cdot (e^{\nu} \wedge e^{\mu})\) and summation convention:

\begin{equation}
F = \inv{2} F^{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu}).
\end{equation}

It is not hard to see that the representation with respect to the reciprocal frame, with
\(F_{{\mu} {\nu}} = F \cdot (e_{\nu} \wedge e_{\mu})\) must be:

\begin{equation}
F = \inv{2} F_{{\mu} {\nu}} (e^{\mu} \wedge e^{\nu}).
\end{equation}

Writing \(F^{\mu\nu}\) or \(F_{\mu\nu}\) leaves a lot unspecified.  You will get a different tensor for each choice of basis.  Using this form amounts to the equivalent of using the matrix of a linear transformation with respect to a specified basis.

\subsection{Electromagnetic tensor components}

Next, let us calculate these
\(F_{{\mu} {\nu}}\), and \(F^{{\mu} {\nu}}\) values and relate them to our electric and magnetic fields so we can work in or translate to and from all of the traditional vector, the tensor, and the Clifford/geometric languages.

\begin{equation*}
F^{{\mu} {\nu}} = \left( E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k} \right) \cdot \gamma^{\nu\mu}.
\end{equation*}

By inspection our electric field components we have:

\begin{equation*}
F^{i0} = E^i,
\end{equation*}

and for the magnetic field:

\begin{equation*}
F^{{i} {j}} = - \epsilon_{k i j} c B^k = - \epsilon_{i j k} c B^k.
\end{equation*}

Putting in sample numbers this is:

\begin{equation}\label{eqn:maxwellToTensor:80}
\begin{aligned}
F^{{3} {2}} &= - \epsilon_{3 2 1} c B^1 = c B^1 \\
F^{{1} {3}} &= - \epsilon_{1 3 2} c B^2 = c B^2 \\
F^{{2} {1}} &= - \epsilon_{2 1 3} c B^3 = c B^3.
\end{aligned}
\end{equation}

This can be summarized in matrix form:

\begin{equation}\label{eqn:maxToTensor:matrixtensor}
F^{\mu\nu} =
\begin{bmatrix}
0   & -E^1 & -E^2 & -E^3 \\
E^1 &   0  & -c B^3 &  c B^2 \\
E^2 &  c B^3 &   0  & -c B^1 \\
E^3 & -c B^2 &  c B^1 &   0
\end{bmatrix}
.
\end{equation}

Observe that no specific reference to a metric was required to evaluate these components.

\subsection{reciprocal tensor (name?)}

The reciprocal frame representation of \eqnref{eqn:maxToTensor:Fcomp} is %metric dependent when expressed

\begin{equation}\label{eqn:maxwellToTensor:100}
\begin{aligned}
F
&= E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k} \\
&= -E^i \gamma^{i 0} - \epsilon_{i j k} c B^i \gamma^{j k}.
\end{aligned}
\end{equation}

%FIXME: WHAT AM I TALKING ABOUT HERE "is metric dependent"?

Calculation of the reciprocal representation of the field tensor \(F_{{\mu} {\nu}} = F \cdot \gamma_{\nu\mu}\) is now possible, and by inspection
%, regardless of the metric:

\begin{equation}\label{eqn:maxwellToTensor:120}
\begin{aligned}
F_{i0} &= -E^i = -F^{i0} \\
F_{ij} &= - \epsilon_{i j k} c B^k = F^{ij}.
\end{aligned}
\end{equation}

So, all the electric field components in the tensor have inverted sign:
\begin{equation*}
F_{\mu\nu} =
\begin{bmatrix}
0   & E^1 & E^2 & E^3 \\
-E^1 &   0  & -c B^3 &  c B^2 \\
-E^2 &  c B^3 &   0  & -c B^1 \\
-E^3 & -c B^2 &  c B^1 &   0  \\
\end{bmatrix}
.
\end{equation*}

This is metric independent with this bivector based definition of \(F_{\mu\nu}\), and \(F^{\mu\nu}\).  Surprising, since I thought I had read otherwise.

\subsection{Lagrangian density}

\citep{doran2003gap}
%Doran/Lasenby
write the Lagrangian density in terms of \(\gpgradezero{F^2}\), whereas Denker writes it in terms of \(\gpgradezero{F \tilde{F}}\).  Is their
alternate choice in metric responsible for this difference.

Reversing the field since it is a bivector, just inverts the sign:

\begin{equation}\label{eqn:maxwellToTensor:140}
\begin{aligned}
F &= E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k} \\
\tilde{F} &= E^i \gamma_{0 i} - \epsilon_{i j k} c B^i \gamma_{k j} = -F.
\end{aligned}
\end{equation}

So the choice of \(\gpgradezero{F^2}\) vs. \(\gpgradezero{F \tilde{F}}\) is just a sign choice, and does not have anything to do with the metric.

Let us evaluate one of these:

\begin{equation}\label{eqn:maxwellToTensor:160}
\begin{aligned}
F^2
&=
(E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k}) (E^u \gamma_{u 0} - \epsilon_{u v w} c B^u \gamma_{v w})  \\
&=
E^i E^u \gamma_{i 0} \gamma_{u 0}
- \epsilon_{u v w} E^i c B^u \gamma_{v w} \gamma_{i 0}
- \epsilon_{i j k} E^u c B^i \gamma_{j k} \gamma_{u 0}
+ \epsilon_{i j k} \epsilon_{u v w} c^2 B^i B^u \gamma_{v w} \gamma_{j k}.
\end{aligned}
\end{equation}

That first term is:

\begin{equation}\label{eqn:maxwellToTensor:180}
\begin{aligned}
E^i E^u \gamma_{i 0} \gamma_{u 0}
&= \BE^2 + \sum_{i \ne j} E^i E^j ( \sigma_i \sigma_j + \sigma_j \sigma_i ) \\
&= \BE^2 + \sum_{i \ne j} 2 E^i E^j \sigma_i \cdot \sigma_j \\
&= \BE^2.
\end{aligned}
\end{equation}

Hmm.  This is messy.  Let us try with \(F = \BE + i c \BB\) directly (with the Doran/Lasenby convention: \(\BE = E^k \sigma_k\)) :

\begin{equation}\label{eqn:maxwellToTensor:200}
\begin{aligned}
F^2
&= (\BE + i c \BB) (\BE + i c \BB) \\
&= \BE^2 + c^2 (i \BB) (i \BB) + c (i \BB \BE + \BE i \BB) \\
&= \BE^2 + c^2 (\BB i) (i \BB) + i c (\BB \BE + \BE \BB) \\
&= \BE^2 - c^2 \BB^2 + 2 i c (\BB \cdot \BE).
\end{aligned}
\end{equation}

\subsubsection{Compared to tensor form}

Now lets compare to the tensor form, where the Lagrangian density is written in terms of the product of upper and lower index tensors:

\begin{equation}\label{eqn:maxwellToTensor:220}
\begin{aligned}
F_{\mu\nu}F^{\mu\nu}
&= F_{i 0}F^{i 0} +F_{0 i}F^{0 i} +\sum_{i<j} F_{i j}F^{i j} +\sum_{j<i} F_{i j}F^{i j} \\
&= 2 F_{i 0}F^{i 0} + 2 \sum_{i<j} F_{i j}F^{i j} \\
&= 2 (-E^i)(E^i) + 2 \sum_{i<j} (F^{i j})^2 \\
&= -2 \BE^2 + 2 \sum_{i<j} ( -\epsilon_{ijk} c B^k )^2 \\
&= -2 ( \BE^2 - c^2 \BB^2 ).
\end{aligned}
\end{equation}

Summarizing with a comparison of the bivector and tensor forms we have:

\begin{equation}
\inv{2} F_{\mu\nu}F^{\mu\nu} = c^2 \BB^2 - \BE^2 = - \gpgradezero{F^2} = \gpgradezero{ F \tilde{F} }.
\end{equation}

But to put this in context we need to figure out how to apply this in the Lagrangian.  That appears to require a potential formulation of the field equations, so that is the next step.

\subsubsection{Potential and relation to electromagnetic tensor}

Since the field is a bivector is it reasonable to assume that it may be possible to express as the curl of a vector

\begin{equation*}
F = \grad \wedge A.
\end{equation*}

Inserting this into the field equation we have:
\begin{equation}\label{eqn:maxwellToTensor:240}
\begin{aligned}
\grad (\grad \wedge A)
&= \grad \cdot (\grad \wedge A) + \mathLabelBox{\grad \wedge \grad}{\(=0\)} \wedge A \\
&= \grad^2 A - \grad ( \grad \cdot A ) \\
&= \inv{\epsilon_0 c} J.
\end{aligned}
\end{equation}

With application of the gauge condition \(\grad \cdot A = 0\), one is left with the four scalar equations:

\begin{equation}\label{eqn:maxToTensor:potential}
\grad^2 A = \inv{\epsilon_0 c} J.
\end{equation}

This can also be seen more directly since the gauge condition implies:

\begin{equation*}
\grad \wedge A = \grad \wedge A + \grad \cdot A = \grad A,
\end{equation*}

from which \eqnref{eqn:maxToTensor:potential} follows directly.  Observe that although the field equation was not metric
dependent, the equivalent potential equation is since it has a squared Laplacian.

\subsubsection{Index raising or lowering}
Any raising or lowering of indices, whether it be in the partials or the basis vectors corresponds to a multiplication by a \((\gamma_{\alpha})^2 = \pm 1\) value, so doing this twice cancels out \((\pm 1)^2 = 1\).

Vector coordinates in the reciprocal basis is translated by such a squared
factor when we are using an orthonormal basis:

\begin{equation}\label{eqn:maxwellToTensor:260}
\begin{aligned}
x
&= \sum \gamma^{\mu} ( \gamma_{\mu} \cdot x ) \\
&= \sum \gamma^{\mu} x_{\mu} \\
&= \sum \gamma^{\mu} (\gamma^{\mu} \gamma_{\mu}) x_{\mu} \\
&= \sum (\gamma^{\mu})^2 \gamma_{\mu} x_{\mu},
\end{aligned}
\end{equation}

therefore

\begin{equation*}
x^{\mu} = x \cdot \gamma^{\mu} = (\gamma^{\mu})^2 x_{\mu}.
\end{equation*}

Similarly our partial derivatives can be raised or lowered since they are just derivatives in terms of one of the choices of coordinates

\begin{equation*}
\partial_{\mu} = \PD{x^{\mu}}{} = \PD{(\gamma_{\mu})^2 x_{\mu}}{} = (\gamma_{\mu})^2 \PD{x_{\mu}}{} = (\gamma_{\mu})^2 \partial^{\mu},
\end{equation*}

when written as a gradient, we have two pairs of \((\gamma_{\mu})^2\) factors that cancel if we switch both indices:

\begin{equation*}
\grad = \gamma^{\mu} \PD{x^{\mu}}{} = (\gamma_{\mu})^2 (\gamma_{\mu})^2 \gamma_{\mu} \PD{x_{\mu}}{} = (\pm 1)^2 \gamma_{\mu} \PD{x_{\mu}}{}.
\end{equation*}

Or in short with the notation above

\begin{equation*}
\grad = \gamma^{\mu} \partial_{\mu} = \gamma_{\mu} \partial^{\mu}.
\end{equation*}

\subsubsection{Back to tensor in terms of potential}
Utilizing matched raising and lowering of indices, our field can be written in any of the following ways
%This metric dependency also shows up if one calculates the em tensor in terms of potential.

\begin{equation}\label{eqn:maxwellToTensor:280}
\begin{aligned}
\grad \wedge A
&= {\gamma_{\mu}} \wedge \gamma_{\nu} \partial^{\mu} A^{\nu} = \sum_{\mu<\nu} {\gamma_{\mu}} \wedge \gamma_{\nu} \left( \partial^{\mu} A^{\nu} - \partial^{\nu} A^{\mu} \right) \\
&= {\gamma^{\mu}} \wedge \gamma^{\nu} \partial_{\mu} A_{\nu} = \sum_{\mu<\nu} {\gamma^{\mu}} \wedge \gamma^{\nu} \left( \partial_{\mu} A_{\nu} - \partial_{\nu} A_{\mu} \right) \\
&= {\gamma_{\mu}} \wedge \gamma^{\nu} \partial^{\mu} A_{\nu} = \sum_{\mu<\nu} {\gamma_{\mu}} \wedge \gamma^{\nu} \left( \partial^{\mu} A_{\nu} - \partial_{\nu} A^{\mu} \right) \\
&= {\gamma^{\mu}} \wedge \gamma_{\nu} \partial_{\mu} A^{\nu} = \sum_{\mu<\nu} {\gamma^{\mu}} \wedge \gamma_{\nu} \left( \partial_{\mu} A^{\nu} - \partial^{\nu} A_{\mu} \right).
\end{aligned}
\end{equation}

These implicitly define the tensor in terms of potential, so we can write:
Calculating the tensor in terms of the bivector we have:

\begin{equation}\label{eqn:maxToTensor:tensorpot}
\begin{aligned}
F^{\mu\nu} &= F \cdot (\gamma^{\nu} \wedge \gamma^{\mu}) = \partial^{\mu} A^{\nu} - \partial^{\nu} A^{\mu} \\
F_{\mu\nu} &= F \cdot (\gamma_{\nu} \wedge \gamma_{\mu}) = \partial_{\mu} A_{\nu} - \partial_{\nu} A_{\mu} \\
{F^{\mu}}_{\nu} &= F \cdot (\gamma^{\nu} \wedge \gamma_{\mu}) = \partial^{\mu} A_{\nu} - \partial_{\nu} A^{\mu} \\
{F_{\mu}}^{\nu} &= F \cdot (\gamma_{\nu} \wedge \gamma^{\mu}) = \partial_{\mu} A^{\nu} - \partial^{\nu} A_{\mu}.
\end{aligned}
\end{equation}

These potential based equations of \eqnref{eqn:maxToTensor:tensorpot}, are consistent with the definition of the field tensor in terms of potential in the
\href{http://en.wikipedia.org/wiki/Covariant\_formulation\_of\_classical\_electromagnetism}{ wikipedia Covariant electromagnetism } article.
That article's definition of the field tensor is also consistent with the field tensor in matrix form of \eqnref{eqn:maxToTensor:matrixtensor}.

However, the \href{http://en.wikipedia.org/wiki/Electromagnetic_tensor}{wikipedia Electromagnetic Tensor}
uses different conventions (at the time of this writing), but both claim a \(-+++\) metric, so I think one is wrong.  I had naturally favor the
covariant article since it agrees with my results.

\subsection{Field equations in tensor form}

\begin{equation}\label{eqn:maxwellToTensor:300}
\begin{aligned}
J/c \epsilon_0
&= \grad (\grad \wedge A) \\
&= \grad \cdot ( \grad \wedge A ) + \grad \wedge \grad \wedge A.
\end{aligned}
\end{equation}

This produces two equations
\begin{equation*}
\grad \cdot ( \grad \wedge A ) = J/c \epsilon_0
\end{equation*}
\begin{equation*}
\grad \wedge \grad \wedge A = 0.
\end{equation*}

\subsubsection{Vector equation part}

Expanding the first in coordinates we have
\begin{equation}\label{eqn:maxwellToTensor:320}
\begin{aligned}
J/c \epsilon_0
&= \gamma^{\alpha} \partial_{\alpha} \cdot ( \gamma^{\mu} \wedge \gamma_{\nu} \partial_{\mu} A^{\nu} ) \\
&= (\gamma^{\alpha} \cdot \gamma_{\mu\nu}) \partial_{\alpha} \partial^{\mu} A^{\nu} \\
&= (
%%\gamma^{\alpha} \cdot \gamma_{\mu}_{\nu}
\delta^{\alpha}_{\mu} \gamma_{\nu}
-\delta^{\alpha}_{\nu} \gamma_{\mu}
) \partial_{\alpha} \partial^{\mu} A^{\nu} \\
&= ( \gamma_{\nu} \partial_{\mu} - \gamma_{\mu} \partial_{\nu} ) \partial^{\mu} A^{\nu} \\
&= \gamma_{\nu} \partial_{\mu} (\partial^{\mu} A^{\nu} -\partial^{\nu} A^{\mu} ) \\
&= \gamma_{\nu} \partial_{\mu} F^{\mu\nu}.
\end{aligned}
\end{equation}

Dotting the LHS with \(\gamma^{\alpha}\) we have
\begin{equation}\label{eqn:maxwellToTensor:340}
\begin{aligned}
\gamma^{\alpha} \cdot J/c \epsilon_0
&= \gamma^{\alpha} \cdot \gamma_{\beta }J^{\beta}/c \epsilon_0 \\
&= \delta^{\alpha}_{\beta }J^{\beta}/c \epsilon_0 \\
&= J^{\alpha}/c \epsilon_0.
\end{aligned}
\end{equation}

and for the RHS
\begin{equation}\label{eqn:maxwellToTensor:360}
\begin{aligned}
\gamma^{\alpha} \cdot \gamma_{\nu} \partial_{\mu} F^{\mu\nu}
&= \partial_{\mu} F^{\mu\alpha}.
\end{aligned}
\end{equation}

Or,
\begin{equation}
\partial_{\mu} F^{\mu\alpha} = J^{\alpha}/c \epsilon_0.
\end{equation}

This is exactly (with index switch) the tensor equation in
\href{http://en.wikipedia.org/wiki/Covariant\_formulation\_of\_classical\_electromagnetism}{ wikipedia Covariant electromagnetism } article.
It however, differs from the
\href{http://en.wikipedia.org/wiki/Electromagnetic_tensor}{wikipedia Electromagnetic Tensor} article.

\subsubsection{Trivector part}

Now, the trivector part of this equation does not seem like it is worth much consideration

\begin{equation}
\grad \wedge \grad \wedge A = 0.
\end{equation}

But this is four of the eight traditional Maxwell's equations when written out in terms of coordinates.  Let us write this out in tensor form
and see how this follows.

\begin{equation}\label{eqn:maxwellToTensor:380}
\begin{aligned}
\grad \wedge \grad \wedge A
&= (\gamma^{\alpha} \partial_{\alpha}) \wedge (\gamma^{\beta} \partial_{\beta}) \wedge (\gamma^{\sigma} A_{\sigma}) \\
&= (\gamma^{\alpha} \wedge \gamma^{\beta} \wedge \gamma^{\sigma}) \partial_{\alpha} \partial_{\beta} A_{\sigma} \\
&=
\inv{2}
(\gamma^{\alpha} \wedge \gamma^{\beta} \wedge \gamma^{\sigma}) \partial_{\alpha} \partial_{\beta} A_{\sigma}
+
\inv{2}
(\gamma^{\alpha} \wedge \gamma^{\sigma} \wedge \gamma^{\beta}) \partial_{\alpha} \partial_{\sigma} A_{\beta}
\\
&=
\inv{2}(\gamma^{\alpha} \wedge \gamma^{\beta} \wedge \gamma^{\sigma}) \partial_{\alpha} (\partial_{\beta} A_{\sigma} - \partial_{\sigma} A_{\beta}) \\
&= \inv{2}(\gamma^{\alpha} \wedge \gamma^{\beta} \wedge \gamma^{\sigma}) \partial_{\alpha} F_{\beta\sigma}.
\end{aligned}
\end{equation}

For each of the four trivectors that span the trivector space the coefficients of those trivectors must all therefore equal zero.  The duality set

\begin{equation*}
\{ i \gamma^{\mu} \}
\end{equation*}

can be used to enumerate these four equations, so to separate these from the wedge products we have to perform the dot products.  Here \(i\) can be any pseudoscalar
associated with the four vector space, and it will be convenient to use an "index-up" pseudoscalar \(i=\gamma^{0123}\).   This will still anticommute with any of the \(\gamma^{\mu}\) vectors.

\begin{equation}\label{eqn:maxwellToTensor:400}
\begin{aligned}
(\gamma^{\alpha} \wedge \gamma^{\beta} \wedge \gamma^{\sigma}) \cdot ( i \gamma^{\mu} )
&= \gpgradezero{ (\gamma^{\alpha} \wedge \gamma^{\beta} \wedge \gamma^{\sigma}) ( i \gamma^{\mu} ) } \\
&= -\gpgradezero{ \gamma^{\alpha} \gamma^{\beta} \gamma^{\sigma} \gamma^{\mu 0123} } \\
&= -\gpgradezero{ \gamma^{\alpha \beta \sigma \mu 0123} } \\
&= \epsilon^{ \alpha \beta \sigma \mu }.
\end{aligned}
\end{equation}

The last line follows with the observation that the scalar part will be zero unless \(\alpha\), \(\beta\), \(\sigma\), and \(\mu\) are all unique.  When they are \(0,1,2,3\) for example then we have \(i^2 = -1\), and any odd permutation will change the sign.

% i^2 : metric independent
%i^2
%=01230123
%=-00123123
%=-00112323
%=00112233
%=00 (\pm 1)^2 33
%=00 33
%=-1

Application of this to our curl of curl expression we have

\begin{equation*}
(\grad \wedge \grad \wedge A) \cdot (i \gamma^{\mu} ) = \inv{2}\epsilon^{ \alpha \beta \sigma \mu } \partial_{\alpha} F_{\beta\sigma}.
\end{equation*}

Because there are no magnetic sources, the one-half scale factor can be dropped, which leaves the remaining four equations of Maxwell's equation in standard tensor form

\begin{equation}
\epsilon^{ \alpha \beta \sigma \mu } \partial_{\alpha} F_{\beta\sigma} = 0.
\end{equation}

One of these will be Gauss's law \(\spacegrad \cdot \BB = 0\), and the other three can be summed in vector form for Faraday's law \(\spacegrad \cross \BE + \PD{t}{\BB} = 0\).

\subsection{Lagrangian density in terms of potential}

We have seen that we can write the core of the Lagrangian density in two forms:

\begin{equation*}
\inv{2} F_{\mu\nu}F^{\mu\nu} = -\gpgradezero{F^2} = c^2 \BB^2 -\BE^2,
\end{equation*}

where summarizing the associated relations we have:

\begin{equation*}
F = \BE + i c \BB = \inv{2} F^{\mu\nu} \gamma_{\mu\nu} = \grad \wedge A = E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k}
\end{equation*}
\begin{equation}\label{eqn:maxwellToTensor:420}
\begin{aligned}
F^{\mu\nu} &= \partial^{\mu} A^{\nu} - \partial^{\nu} A^{\mu} \\
F_{\mu\nu} &= \partial_{\mu} A_{\nu} - \partial_{\nu} A_{\mu} \\
F^{i0} &= E^i = -F_{i0} \\
F^{ij} &= -\epsilon_{i j k} c B^k = F_{ij}.
\end{aligned}
\end{equation}

Now, if we want the density in terms of potential, by inspection we can form this from the tensor as:

\begin{equation*}
\inv{2} F_{\mu\nu}F^{\mu\nu} = \inv{2} (\partial_{\mu} A_{\nu} - \partial_{\nu} A_{\mu} ) (\partial^{\mu} A^{\nu} - \partial^{\nu} A^{\mu} ).
\end{equation*}

We should also be able to calculate this directly from the bivector square.  Lets verify this:

\begin{equation}\label{eqn:maxwellToTensor:440}
\begin{aligned}
\gpgradezero{ F^2 }
&= \gpgradezero{ (\grad \wedge A)(\grad \wedge A) } \\
&= \gpgradezero{ (\gamma^{\mu} \wedge \gamma_{\nu} \partial_{\mu} A^{\nu}) (\gamma^{\alpha} \wedge \gamma_{\beta} \partial_{\alpha} A^{\beta}) } \\
&= (\gamma^{\mu} \wedge \gamma^{\nu} \partial_{\mu} A_{\nu}) \cdot (\gamma_{\alpha} \wedge \gamma_{\beta} \partial^{\alpha} A^{\beta}) \\
&= ( ( (\gamma^{\mu} \wedge \gamma^{\nu}) \cdot \gamma_{\alpha} ) \cdot \gamma_{\beta} ) \partial_{\mu} A_{\nu} \partial^{\alpha} A^{\beta} \\
&= \left( \delta^{\mu}_{\beta} \delta^{\nu}_{\alpha} - \delta^{\mu}_{\alpha} \delta^{\nu}_{\beta} \right) \partial_{\mu} A_{\nu} \partial^{\alpha} A^{\beta} \\
&= \partial_{\mu} A_{\nu} \partial^{\nu} A^{\mu} - \partial_{\mu} A_{\nu} \partial^{\mu} A^{\nu} \\
&= \partial_{\mu} A_{\nu} \left( \partial^{\nu} A^{\mu} - \partial^{\mu} A^{\nu} \right) \\
&=
\inv{2} \left( \partial_{\mu} A_{\nu} \left( \partial^{\nu} A^{\mu} - \partial^{\mu} A^{\nu} \right)
+\partial_{\nu} A_{\mu} \left( \partial^{\mu} A^{\nu} - \partial^{\nu} A^{\mu} \right) \right)
\\
&= \inv{2} \left( \partial_{\nu} A_{\mu} - \partial_{\mu} A_{\nu} \right) \left( \partial^{\nu} A^{\mu} - \partial^{\mu} A^{\nu} \right) \\
&= -\inv{2} F_{\mu\nu}F^{\mu\nu},
\end{aligned}
\end{equation}

as expected.

The factor of \(1/2\) appearance is a \(x = (1/2)(x + x)\) operation, plus a switch of dummy indices in one half of the sum.

With the density expanded completely in terms of potentials things are in a form for an attempt to
evaluate the Lagrangian equations or do the
variational exercise (as in Feynman
\citep{feynman1963flp}
with the electrostatic case) and see that this recovers the field equations (covered in a subsequent set of notes in both fashions).
